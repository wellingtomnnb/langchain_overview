{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "client = openai.Client()\n",
    "\n",
    "vector_store = client.beta.vector_stores.create(name=\"Tutor de Apostilas\")\n",
    "\n",
    "file = [\"data_sample/LLM.pdf\"]\n",
    "file_stream = [open(f, \"rb\") for f in file]\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id = vector_store.id,\n",
    "  files=file_stream\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Tutor Apostila\",\n",
    "  instructions=\"Você é um tutor especializado em tecnologias emergentes. \\\n",
    "    Você sabe responder perguntas sobre LLMs como OpenAI, HuggingFace, Gemini, etc. \\\n",
    "    Caso você não encontre as respostas, seja sincero e fale que não sabe responder\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\":[vector_store.id]}},\n",
    "  model=\"gpt-4-turbo-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_6UOAq5UrlM9JJAI5kp1btNJf', assistant_id='asst_nPJ7RQTHY468WqvGQpRLd37L', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=657, file_citation=FileCitation(file_id='file-HCt9HngfKnouSrBJdkLvAC'), start_index=644, text='【4:0†LLM.pdf】', type='file_citation')], value='O Hugging Face é destacado como uma comunidade de código aberto que congrega centenas de milhares de modelos de contribuidores que podem auxiliar na resolução de muitos casos de uso específicos, tais como geração de texto, resumo e classificação. Tais comunidades estão rapidamente se aproximando do desempenho de modelos proprietários, embora ainda não tenham conseguido igualar o desempenho de modelos avançados como o GPT-4. Contudo, a comunidade de código aberto exige um pouco mais de esforço para pegar um modelo e começar a utilizá-lo, embora avanços estejam acontecendo rapidamente para tornar esses modelos mais acessíveis aos usuários【4:0†LLM.pdf】.\\n\\nA Gekar, por sua vez, não é explicitamente mencionada no contexto de utilização do Hugging Face dentro dos resultados da pesquisa. Isso pode indicar que as informações sobre a utilização específica do Hugging Face pela Gekar não estejam disponíveis no documento fornecido ou não tenham sido abordadas diretamente na consulta realizada.'), type='text')], created_at=1743526046, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_SChfiQmgcVoHH0yZKOHSxdJ4', status=None, thread_id='thread_Bc8UB6klA0rlj62i7Bzbqwzw'), Message(id='msg_JhrOWCxXcjL4p5GbbT3Bvey1', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Conforme o documento, o que é o Hugging Face e como a empres Gekar tem utilizado ela?'), type='text')], created_at=1743526040, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_Bc8UB6klA0rlj62i7Bzbqwzw')], object='list', first_id='msg_6UOAq5UrlM9JJAI5kp1btNJf', last_id='msg_JhrOWCxXcjL4p5GbbT3Bvey1', has_more=False)\n",
      "O Hugging Face é destacado como uma comunidade de código aberto que congrega centenas de milhares de modelos de contribuidores que podem auxiliar na resolução de muitos casos de uso específicos, tais como geração de texto, resumo e classificação. Tais comunidades estão rapidamente se aproximando do desempenho de modelos proprietários, embora ainda não tenham conseguido igualar o desempenho de modelos avançados como o GPT-4. Contudo, a comunidade de código aberto exige um pouco mais de esforço para pegar um modelo e começar a utilizá-lo, embora avanços estejam acontecendo rapidamente para tornar esses modelos mais acessíveis aos usuários【4:0†LLM.pdf】.\n",
      "\n",
      "A Gekar, por sua vez, não é explicitamente mencionada no contexto de utilização do Hugging Face dentro dos resultados da pesquisa. Isso pode indicar que as informações sobre a utilização específica do Hugging Face pela Gekar não estejam disponíveis no documento fornecido ou não tenham sido abordadas diretamente na consulta realizada.\n"
     ]
    }
   ],
   "source": [
    "question = \"Conforme o documento, o que é o Hugging Face e como a empres Gekar tem utilizado ela?\"\n",
    "\n",
    "# Criação da thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=question\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Nome do usuário Premium\"\n",
    ")\n",
    "\n",
    "# Aguarda thread rodar\n",
    "while run.status in ['queued', \"in_progress\", \"cancelling\"]:\n",
    "  time.sleep(1)\n",
    "  run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "# Verifica a resposta\n",
    "if run.status == \"completed\":\n",
    "  msgs = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "  print(msgs)\n",
    "else: print(f\"Error {run.status}\")\n",
    "\n",
    "print(msgs.data[0].content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
